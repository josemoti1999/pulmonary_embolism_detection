{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "3_rsna_pulmonary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo8E4yIwni5nF0LYcd0mWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josemoti1999/pulmonary_embolism_detection/blob/main/3_rsna_pulmonary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqkShsLhnEdi"
      },
      "source": [
        "* Experiment4 - with B0\n",
        "* Experiment5 - with B7 - no label smoothing\n",
        "* Experiment6 - with b5 - no label smoothing\n",
        "* Experiment7 - b5 and imageposition - create new tfrecords with image position\n",
        "* Experiment12 - with image position\n",
        "* Experiment 13 - with efnetb7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnp3ihaCMSHI",
        "outputId": "404cd9b5-9dee-4aac-dbff-6660f5803129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEXMAIpeMdZU"
      },
      "source": [
        "colab = 1\n",
        "FOLDER = 'Experiment_13'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcGxcvkeMgIR"
      },
      "source": [
        "!pip install -q efficientnet\n",
        "!pip install -q gcsfs\n",
        "import os\n",
        "import re, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import efficientnet.tfkeras as efn\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from collections import namedtuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUinek48MkRi"
      },
      "source": [
        "!pip install -q tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "import requests\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xptq52HQM0g9",
        "outputId": "b15b8f98-6f67-4fd3-9ee7-5b281b006ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "PATH = '/content/drive/My Drive/Kaggle/rsna_pulmonary'\n",
        "PATH = os.path.join(PATH, FOLDER)\n",
        "os.makedirs(PATH, exist_ok=True)\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Kaggle/rsna_pulmonary/Experiment_13'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xHw5QmFM3QS",
        "outputId": "40422b10-01d8-46a4-8b6b-7d021a65d962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.89.49.106:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.49.106:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.89.49.106:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKXVf-WYNC_6"
      },
      "source": [
        "BATCH_SIZE_PER_REPLICA = 32\n",
        "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
        "IMAGE_SIZE = [256, 256]\n",
        "SEED = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqlFU86HNVvZ"
      },
      "source": [
        "GCS_PATHS = [\n",
        "'gs://kds-675a4d0ca17253f876424309f74145c1167e831dc34c32522a29e4a9',\n",
        "'gs://kds-1077ea6ef5bd8d0ba8150b786cee31c1c897708727eeb60a5fc2c0cd',\n",
        "'gs://kds-1bc7664eb4ada6b80cb8c57e621c6cb78f2092fb164aea1302bd77a3',\n",
        "'gs://kds-19a534b62267f9fe27cf1640e8781e6c04fd661d6b67ac160f1cc746',\n",
        "'gs://kds-b5a1644b1f9084284cb2f724b41a5501d7fa4c9e5c4eb99a5a8d602f',\n",
        "'gs://kds-f928be364facd6fe31db68406c543692388b880e8c7585f4c0403573',\n",
        "'gs://kds-1a521e2e4a90df381780b48a4ce28e63764e7bec29805c8d6d6861e2',\n",
        "'gs://kds-407358bc70721c44703d11afe83bdf2e970449eb110f376d01223862',\n",
        "'gs://kds-db1695bd356de02fb8b89de44067a54e1db12f99675678d5e92b5917',\n",
        "'gs://kds-2d74bd2971f4de2c28e3a427d05381f967de5070458b20031273e0f8',\n",
        "'gs://kds-80c22cf93ec97373e7bbdc091dc2f9f7358e4c08d85797cdf86d9723',\n",
        "'gs://kds-981f9b6ce021f08600630510b5398dafaca9ef15de304a20f083c886',\n",
        "'gs://kds-54fafeca23b3db6855d075ce547486a53f37f981e0100552e714f561',\n",
        "'gs://kds-9c42ec420192f5d63b360164ad37ed81dbfe7afc16a4e4fac418e952',\n",
        "'gs://kds-1bc45eb2a6dcbb73ace5842a7b5c01effd9a3230f9b8c73314a26d74'\n",
        "]\n",
        "\n",
        "DICT_PATH = 'gs://kds-baad38a91ebb50744b66774d8ba77e8d3df2ce699dc5f8ad2d5dc6f6/train_with_metadata.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfEqWkDKOxS4",
        "outputId": "cb69791d-bd6a-4a54-b63e-1815255a83d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "FILENAMES=[]\n",
        "for GCS_PATH in GCS_PATHS:     \n",
        "    FILENAMES += tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
        "TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(FILENAMES, test_size = 0.02, random_state = SEED)\n",
        "training_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in TRAINING_FILENAMES]\n",
        "validation_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in VALIDATION_FILENAMES]\n",
        "print(training_groups, validation_groups)\n",
        "\n",
        "df = pd.read_csv(DICT_PATH).set_index('SOPInstanceUID')\n",
        "def count_data_items(filenames):\n",
        "    records = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    n = df[df['fold'].isin(records)].shape[0]\n",
        "    return n\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES  = count_data_items(VALIDATION_FILENAMES)\n",
        "print(f'Training with {NUM_TRAINING_IMAGES} images')\n",
        "print(f'Validating with {NUM_VALIDATION_IMAGES} images')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 12, 13, 6, 10, 5, 2, 4, 0, 11, 7, 3, 14, 8] [9]\n",
            "Training with 1671055 images\n",
            "Validating with 119539 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExyfE3WoP0_n"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    #image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example, return_id):\n",
        "    TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"id\" : tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_position\" : tf.io.FixedLenFeature([], tf.float32),\n",
        "        \"q_i\" : tf.io.FixedLenFeature([], tf.float32)\n",
        "        }\n",
        "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    target = tf.cast(tf.expand_dims(example['target'],axis=0), tf.int32)\n",
        "    image_id = example['id']\n",
        "    image_position = tf.cast(example['image_position'], tf.float32)\n",
        "    q_i = tf.cast(example['q_i'], tf.float32)\n",
        "    if return_id:\n",
        "        return (image,image_position), q_i, image_id\n",
        "    return (image,image_position), q_i, target\n",
        "\n",
        "def load_dataset(filenames, ordered, return_id=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False   \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    dataset = dataset.map(lambda example:read_tfrecord(example, return_id=return_id), num_parallel_calls = AUTO) \n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset(filenames, ordered):\n",
        "    dataset = load_dataset(filenames, ordered = ordered)\n",
        "    dataset = dataset.repeat() \n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(filenames, ordered):\n",
        "    dataset = load_dataset(filenames, ordered = ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) \n",
        "    return dataset\n",
        "\n",
        "def get_prediction_dataset(filenames, ordered, return_id):\n",
        "    dataset = load_dataset(filenames, ordered=ordered, return_id=True)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngPv5-iaGMH"
      },
      "source": [
        "@tf.function\n",
        "def lrfn(epoch):\n",
        "    LR_START = 0.000001\n",
        "    LR_MAX = 0.000005 * strategy.num_replicas_in_sync\n",
        "    LR_MIN = 0.000001\n",
        "    LR_RAMPUP_EPOCHS = 5\n",
        "    LR_SUSTAIN_EPOCHS = 5\n",
        "    LR_EXP_DECAY = .8\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPS8GLkcRYS9"
      },
      "source": [
        "EPOCHS = 5\n",
        "EFNET = 7\n",
        "RETRAIN = False\n",
        "CUSTOM_LR = True\n",
        "LR = 1e-4\n",
        "MODEL_PATH = '.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdgY555mRqF8",
        "outputId": "2e588f30-b2ff-435e-8979-d25c19b67825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def int_div_round_up(a, b):\n",
        "    return (a + b - 1) // b\n",
        "\n",
        "def calc_loss(true, pred, q_i):\n",
        "    binary_ce_loss = tf.keras.losses.binary_crossentropy(true, pred)\n",
        "    sample_weight = tf.cast(q_i+1e-7,tf.float32)\n",
        "    loss = binary_ce_loss*sample_weight\n",
        "    return loss\n",
        "\n",
        "class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __call__(self, step):\n",
        "        return lrfn(epoch=step//STEPS_PER_EPOCH)\n",
        "\n",
        "seed_everything(SEED)\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "VALIDATION_STEPS = int_div_round_up(NUM_VALIDATION_IMAGES, BATCH_SIZE)\n",
        "\n",
        "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
        "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n",
        "with strategy.scope():\n",
        "    inp1 = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
        "    inp2 = tf.keras.layers.Input(shape = (1), name = 'inp2')\n",
        "    x1 = EFNS[EFNET](weights = 'noisy-student', include_top = False)(inp1)\n",
        "    x1 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
        "    #x2 = tf.keras.layers.Dense(128,activation='relu')(inp2)\n",
        "    #x = tf.keras.layers.concatenate((x1,x2), axis=-1)\n",
        "    output = tf.keras.layers.Dense(1,activation='sigmoid')(x1)\n",
        "    model = tf.keras.models.Model(inputs = (inp1,inp2), outputs = output)\n",
        "\n",
        "    if CUSTOM_LR:\n",
        "        #optimizer = tf.keras.optimizers.Adam(learning_rate=LRSchedule())\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=LRSchedule(), momentum=0.99)\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=LR, momentum=0.99)\n",
        "    \n",
        "    train_auc = tf.keras.metrics.AUC()\n",
        "    val_auc = tf.keras.metrics.AUC()\n",
        "    train_loss = tf.keras.metrics.Sum()\n",
        "    val_loss = tf.keras.metrics.Sum()\n",
        "    train_q_i = tf.keras.metrics.Sum()\n",
        "    val_q_i = tf.keras.metrics.Sum()\n",
        "    loss_fn = lambda true,pred,q_i: tf.nn.compute_average_loss(calc_loss(true,pred,q_i), \n",
        "                                                     global_batch_size=1)\n",
        "    q_i_sum_fn = lambda q_i: tf.nn.compute_average_loss(q_i, global_batch_size=1)\n",
        "\n",
        "if RETRAIN:\n",
        "    print('Loading model...')\n",
        "    model.load_weights(os.path.join(PATH, MODEL_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n",
            "258072576/258068648 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-5MfhcJBvPO",
        "outputId": "40c800fd-f60f-459d-dba0-73e5c1325d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Loading train data...')\n",
        "train_dataset = strategy.experimental_distribute_dataset(get_training_dataset(TRAINING_FILENAMES, ordered = False))\n",
        "print('Loading val data...')\n",
        "val_dataset = strategy.experimental_distribute_dataset(get_validation_dataset(VALIDATION_FILENAMES, ordered = True))\n",
        "print(\"Steps per epoch:\", STEPS_PER_EPOCH)\n",
        "print('Validation steps:', VALIDATION_STEPS)\n",
        "History = namedtuple('History', 'history')\n",
        "history = History(history={'loss': [], 'val_loss': [], 'auc': [], 'val_auc': []})\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, q_i, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        probabilities = model(x, training=True)\n",
        "        loss = loss_fn(target, probabilities, q_i)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    train_auc.update_state(target, probabilities)\n",
        "    train_loss.update_state(loss)\n",
        "    q_i_sum = q_i_sum_fn(q_i)\n",
        "    train_q_i.update_state(q_i_sum)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(x, q_i, target):\n",
        "    probabilities = model(x, training=False)\n",
        "    loss = loss_fn(target, probabilities, q_i)\n",
        "    val_auc.update_state(target, probabilities)\n",
        "    val_loss.update_state(loss)\n",
        "    q_i_sum = q_i_sum_fn(q_i)\n",
        "    val_q_i.update_state(q_i_sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading train data...\n",
            "Loading val data...\n",
            "Steps per epoch: 6527\n",
            "Validation steps: 467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sj5m8Jehp3J",
        "outputId": "e1093ae4-c9aa-4fd1-88d0-b82c7d30dc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "start_time = epoch_start_time = time.time()\n",
        "epoch = 0\n",
        "for step, (x, q_i, target) in enumerate(train_dataset):\n",
        "\n",
        "    strategy.run(train_step, args=(x, q_i, target))\n",
        "    if step%2000==0:\n",
        "        print(step,'--> ''Loss:',train_loss.result().numpy()/train_q_i.result().numpy(),'...','AUC:', train_auc.result().numpy())\n",
        "\n",
        "    if ((step+1) // STEPS_PER_EPOCH) > epoch:\n",
        "        print('|')\n",
        "        for x, q_i, target in val_dataset:\n",
        "            strategy.run(valid_step, args=(x, q_i, target))\n",
        "        history.history['auc'].append(train_auc.result().numpy())\n",
        "        history.history['val_auc'].append(val_auc.result().numpy())\n",
        "        history.history['loss'].append(train_loss.result().numpy()/train_q_i.result().numpy())\n",
        "        history.history['val_loss'].append(val_loss.result().numpy()/val_q_i.result().numpy())\n",
        "\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        print('EPOCH {:d}/{:d}'.format(epoch+1, EPOCHS))\n",
        "        print('time: {:0.1f}s'.format(epoch_time),\n",
        "              'loss: {:0.4f}'.format(history.history['loss'][-1]),\n",
        "              'auc: {:0.4f}'.format(history.history['auc'][-1]),\n",
        "              'val_loss: {:0.4f}'.format(history.history['val_loss'][-1]),\n",
        "              'val_auc: {:0.4f}'.format(history.history['val_auc'][-1]),\n",
        "              'lr: {:0.4g}'.format(lrfn(epoch) if CUSTOM_LR else LR), flush=True)\n",
        "        epoch = (step+1) // STEPS_PER_EPOCH\n",
        "        epoch_start_time = time.time()\n",
        "        train_auc.reset_states()\n",
        "        val_auc.reset_states()\n",
        "        val_loss.reset_states()\n",
        "        train_loss.reset_states()\n",
        "        train_q_i.reset_states()\n",
        "        val_q_i.reset_states()\n",
        "\n",
        "        NUM_INFERENCE_IMAGES  = count_data_items(VALIDATION_FILENAMES)\n",
        "        print(f'Inference with {NUM_INFERENCE_IMAGES} images')\n",
        "        check_dataset = get_validation_dataset(VALIDATION_FILENAMES, ordered = True)\n",
        "        VALIDATION_STEPS = (NUM_INFERENCE_IMAGES // BATCH_SIZE) +1\n",
        "        print('Predicting')\n",
        "        pred = model.predict(check_dataset,steps=VALIDATION_STEPS,verbose=1)\n",
        "        print('Pred shape',pred.shape)\n",
        "        test_dataset = get_prediction_dataset(VALIDATION_FILENAMES, ordered = True, return_id=True)\n",
        "        decoder = lambda x: x.decode(\"utf-8\")\n",
        "        count = 0\n",
        "        for img, q_i, img_name in iter(test_dataset):\n",
        "            img_name=img_name.numpy()\n",
        "            img_name = np.vectorize(decoder)(img_name)\n",
        "            if count==0:\n",
        "                final_array = img_name\n",
        "                count+=1\n",
        "            else:\n",
        "                final_array = np.concatenate((final_array, img_name), axis=0)\n",
        "                count+=1\n",
        "        val_df = pd.DataFrame({'SOPInstanceUID':final_array,'prediction':np.squeeze(pred,axis=-1)})\n",
        "        val_df = pd.merge(val_df, df, on='SOPInstanceUID', how='left')\n",
        "        def calc_image_level_loss(y_true_imag, y_pred_imag, q_image):\n",
        "            score_i =  np.sum(- q_image * (y_true_imag*np.log(y_pred_imag) + (1-y_true_imag)*np.log(1-y_pred_imag))) / np.sum(q_image)\n",
        "            print(\"{}: {:.6f}\".format((\"image_level_weighted_log_loss\" +\" \"*50)[:30], score_i))\n",
        "        calc_image_level_loss(val_df.pe_present_on_image.values, val_df.prediction.values+np.finfo(float).eps, val_df.q_i.values)\n",
        "        \n",
        "        model.save(os.path.join(PATH,'epoch-{}_loss-{:0.4f}_val_loss-{:0.4f}.h5'.format(epoch, history.history['loss'][-1],history.history['val_loss'][-1])))\n",
        "        print('\\n')\n",
        "\n",
        "        if epoch >= EPOCHS:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 --> Loss: 0.70485365 ... AUC: 0.52952754\n",
            "2000 --> Loss: 0.60824543 ... AUC: 0.59188527\n",
            "4000 --> Loss: 0.55309546 ... AUC: 0.67680615\n",
            "6000 --> Loss: 0.50756764 ... AUC: 0.72962826\n",
            "|\n",
            "EPOCH 1/5\n",
            "time: 4955.1s loss: 0.4980 auc: 0.7386 val_loss: 0.3960 val_auc: 0.8165 lr: 1e-06\n",
            "Inference with 119539 images\n",
            "Predicting\n",
            "467/467 [==============================] - 96s 206ms/step\n",
            "Pred shape (119539, 1)\n",
            "image_level_weighted_log_loss : 0.396010\n",
            "\n",
            "\n",
            "8000 --> Loss: 0.38649687 ... AUC: 0.81503505\n",
            "10000 --> Loss: 0.3665863 ... AUC: 0.8233856\n",
            "12000 --> Loss: 0.35745528 ... AUC: 0.82886595\n",
            "|\n",
            "EPOCH 2/5\n",
            "time: 4864.8s loss: 0.3518 auc: 0.8312 val_loss: 0.3199 val_auc: 0.8509 lr: 8.8e-06\n",
            "Inference with 119539 images\n",
            "Predicting\n",
            "467/467 [==============================] - 89s 191ms/step\n",
            "Pred shape (119539, 1)\n",
            "image_level_weighted_log_loss : 0.319933\n",
            "\n",
            "\n",
            "14000 --> Loss: 0.3425019 ... AUC: 0.8429548\n",
            "16000 --> Loss: 0.3281689 ... AUC: 0.8464255\n",
            "18000 --> Loss: 0.3237186 ... AUC: 0.85215294\n",
            "|\n",
            "EPOCH 3/5\n",
            "time: 4844.7s loss: 0.3152 auc: 0.8580 val_loss: 0.3091 val_auc: 0.8805 lr: 1.66e-05\n",
            "Inference with 119539 images\n",
            "Predicting\n",
            "467/467 [==============================] - 89s 192ms/step\n",
            "Pred shape (119539, 1)\n",
            "image_level_weighted_log_loss : 0.309065\n",
            "\n",
            "\n",
            "20000 --> Loss: 0.32100278 ... AUC: 0.8614615\n",
            "22000 --> Loss: 0.29262757 ... AUC: 0.8744054\n",
            "24000 --> Loss: 0.2871828 ... AUC: 0.8818757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAgp1QOf2XbE"
      },
      "source": [
        "# INFERENCE VAL DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWgaVhOuNq1G",
        "outputId": "d0dd994a-a380-4cc0-c2ef-81d5141f5bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_model(ef):\n",
        "    with strategy.scope():\n",
        "        inp1 = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
        "        inp2 = tf.keras.layers.Input(shape = (1), name = 'inp2')\n",
        "        x1 = EFNS[EFNET](weights = 'noisy-student', include_top = False)(inp1)\n",
        "        x1 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
        "        #x2 = tf.keras.layers.Dense(128,activation='relu')(inp2)\n",
        "        #x = tf.keras.layers.concatenate((x1,x2), axis=-1)\n",
        "        output = tf.keras.layers.Dense(1,activation='sigmoid')(x1)\n",
        "        model = tf.keras.models.Model(inputs = (inp1,inp2), outputs = output)\n",
        "        return model\n",
        "\n",
        "EFNET = 5\n",
        "NEW_MODEL = True\n",
        "MODEL_PATH = 'epoch-2_loss-0.2604_val_loss-0.2779.h5'\n",
        "if NEW_MODEL:\n",
        "    model = get_model(ef=EFNET)\n",
        "    print('Loading model...')\n",
        "    model.load_weights(os.path.join(PATH, MODEL_PATH))\n",
        "#with strategy.scope():\n",
        "    #embedding = model.layers[-2].output\n",
        "    #model = tf.keras.models.Model(inputs=model.input, outputs=embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gat2Ly1V2XbF",
        "outputId": "759504ea-b43d-40ae-c06c-a1f47cdcfe33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "NUM_INFERENCE_IMAGES  = count_data_items(VALIDATION_FILENAMES)\n",
        "print(f'Inference with {NUM_INFERENCE_IMAGES} images')\n",
        "check_dataset = get_validation_dataset(VALIDATION_FILENAMES, ordered = True)\n",
        "VALIDATION_STEPS = (NUM_INFERENCE_IMAGES // BATCH_SIZE) +1\n",
        "\n",
        "print('Predicting')\n",
        "pred = model.predict(check_dataset,steps=VALIDATION_STEPS,verbose=1)\n",
        "\n",
        "print('pred min/max ',pred.min(), pred.max())\n",
        "print('pred shape',pred.shape)\n",
        "test_dataset = get_prediction_dataset(VALIDATION_FILENAMES, ordered = True, return_id=True)\n",
        "decoder = lambda x: x.decode(\"utf-8\")\n",
        "count = 0\n",
        "for img, q_i, img_name in iter(test_dataset):\n",
        "    img_name=img_name.numpy()\n",
        "    img_name = np.vectorize(decoder)(img_name)\n",
        "    if count==0:\n",
        "        final_array = img_name\n",
        "        count+=1\n",
        "    else:\n",
        "        final_array = np.concatenate((final_array, img_name), axis=0)\n",
        "        count+=1\n",
        "print('final array shape', final_array.shape)\n",
        "\n",
        "val_df = pd.DataFrame({'SOPInstanceUID':final_array,'prediction':np.squeeze(pred,axis=-1)})\n",
        "val_df = pd.merge(val_df, df, on='SOPInstanceUID', how='left')\n",
        "\n",
        "def calc_image_level_loss(y_true_imag, y_pred_imag, q_image):\n",
        "    score_i =  np.sum(- q_image * (y_true_imag*np.log(y_pred_imag) + (1-y_true_imag)*np.log(1-y_pred_imag))) / np.sum(q_image)\n",
        "    print(\"{}: {:.6f}\".format((\"image_level_weighted_log_loss\" +\" \"*50)[:30], score_i))\n",
        "\n",
        "calc_image_level_loss(val_df.pe_present_on_image.values, val_df.prediction.values+np.finfo(float).eps, val_df.q_i.values)\n",
        "\n",
        "dict_ = dict(zip(final_array, pred))\n",
        "with open(os.path.join(PATH, f'mapping_validation_set.p'), 'wb') as fp:\n",
        "    pickle.dump(dict_, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(os.path.join(PATH, f'mapping_validation_set.p'), 'rb') as fp:\n",
        "    data = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference with 119539 images\n",
            "Predicting\n",
            "467/467 [==============================] - 127s 271ms/step\n",
            "pred min/max  0.0 0.99983114\n",
            "pred shape (119539, 1)\n",
            "final array shape (119539,)\n",
            "image_level_weighted_log_loss : 0.278059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW6fD7d_Uwat"
      },
      "source": [
        "# INFERENCE TRAIN DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T87Ejddzii24",
        "outputId": "8dc53b42-f661-4105-bfa0-c20a3643e9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "NUM_INFERENCE_IMAGES  = count_data_items(TRAINING_FILENAMES)\n",
        "print(f'Inference with {NUM_INFERENCE_IMAGES} images')\n",
        "val_dataset = get_validation_dataset(TRAINING_FILENAMES, ordered = True)\n",
        "STEPS_PER_EPOCH = (NUM_INFERENCE_IMAGES // BATCH_SIZE) +1\n",
        "\n",
        "print('Predicting')\n",
        "pred = model.predict(val_dataset,steps=STEPS_PER_EPOCH,verbose=1)\n",
        "\n",
        "print('pred min/max ',pred.min(), pred.max())\n",
        "print('pred shape',pred.shape)\n",
        "test_dataset = get_prediction_dataset(TRAINING_FILENAMES, ordered = True, return_id=True)\n",
        "decoder = lambda x: x.decode(\"utf-8\")\n",
        "count = 0\n",
        "for img, q_i, img_name in iter(test_dataset):\n",
        "    img_name=img_name.numpy()\n",
        "    img_name = np.vectorize(decoder)(img_name)\n",
        "    if count==0:\n",
        "        final_array = img_name\n",
        "        count+=1\n",
        "    else:\n",
        "        final_array = np.concatenate((final_array, img_name), axis=0)\n",
        "        count+=1\n",
        "print('final array shape', final_array.shape)\n",
        "\n",
        "val_df = pd.DataFrame({'SOPInstanceUID':final_array,'prediction':np.squeeze(pred,axis=-1)})\n",
        "val_df = pd.merge(val_df, df, on='SOPInstanceUID', how='left')\n",
        "\n",
        "def calc_image_level_loss(y_true_imag, y_pred_imag, q_image):\n",
        "    score_i =  np.sum(- q_image * (y_true_imag*np.log(y_pred_imag) + (1-y_true_imag)*np.log(1-y_pred_imag))) / np.sum(q_image)\n",
        "    print(\"{}: {:.6f}\".format((\"image_level_weighted_log_loss\" +\" \"*50)[:30], score_i))\n",
        "\n",
        "calc_image_level_loss(val_df.pe_present_on_image.values, val_df.prediction.values+np.finfo(float).eps, val_df.q_i.values)\n",
        "\n",
        "dict_ = dict(zip(final_array, pred))\n",
        "with open(os.path.join(PATH, f'mapping_train_set.p'), 'wb') as fp:\n",
        "    pickle.dump(dict_, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open(os.path.join(PATH, f'mapping_train_set.p'), 'rb') as fp:\n",
        "    data = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference with 1671055 images\n",
            "Predicting\n",
            "6528/6528 [==============================] - 1550s 237ms/step\n",
            "pred min/max  0.0 0.9999092\n",
            "pred shape (1671055, 1)\n",
            "final array shape (1671055,)\n",
            "image_level_weighted_log_loss : 0.208156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBa4uZ5SDoBK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}