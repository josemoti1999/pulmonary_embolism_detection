{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_rsna_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD93RaDU3bah"
      },
      "source": [
        "# Experiment 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnp3ihaCMSHI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1343907d-1291-417c-eb06-3511eb62cad3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEXMAIpeMdZU"
      },
      "source": [
        "colab = 1\n",
        "FOLDER = 'Experiment_14'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcGxcvkeMgIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bf7087d2-f581-4cf0-b02c-3eb89ae48838"
      },
      "source": [
        "!pip install -q gcsfs\n",
        "import os\n",
        "import re, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Bidirectional"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 92kB 4.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 24.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 38.2MB/s \n",
            "\u001b[?25h  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xptq52HQM0g9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b111f39d-100a-4693-ec63-f43186fc8f6a"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Kaggle/rsna_pulmonary'\n",
        "PATH = os.path.join(PATH, FOLDER)\n",
        "os.makedirs(PATH, exist_ok=True)\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Kaggle/rsna_pulmonary/Experiment_14'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqlFU86HNVvZ"
      },
      "source": [
        "GCS_PATHS = [\n",
        "'gs://kds-675a4d0ca17253f876424309f74145c1167e831dc34c32522a29e4a9',\n",
        "'gs://kds-1077ea6ef5bd8d0ba8150b786cee31c1c897708727eeb60a5fc2c0cd',\n",
        "'gs://kds-1bc7664eb4ada6b80cb8c57e621c6cb78f2092fb164aea1302bd77a3',\n",
        "'gs://kds-19a534b62267f9fe27cf1640e8781e6c04fd661d6b67ac160f1cc746',\n",
        "'gs://kds-b5a1644b1f9084284cb2f724b41a5501d7fa4c9e5c4eb99a5a8d602f',\n",
        "'gs://kds-f928be364facd6fe31db68406c543692388b880e8c7585f4c0403573',\n",
        "'gs://kds-1a521e2e4a90df381780b48a4ce28e63764e7bec29805c8d6d6861e2',\n",
        "'gs://kds-407358bc70721c44703d11afe83bdf2e970449eb110f376d01223862',\n",
        "'gs://kds-db1695bd356de02fb8b89de44067a54e1db12f99675678d5e92b5917',\n",
        "'gs://kds-2d74bd2971f4de2c28e3a427d05381f967de5070458b20031273e0f8',\n",
        "'gs://kds-80c22cf93ec97373e7bbdc091dc2f9f7358e4c08d85797cdf86d9723',\n",
        "'gs://kds-981f9b6ce021f08600630510b5398dafaca9ef15de304a20f083c886',\n",
        "'gs://kds-54fafeca23b3db6855d075ce547486a53f37f981e0100552e714f561',\n",
        "'gs://kds-9c42ec420192f5d63b360164ad37ed81dbfe7afc16a4e4fac418e952',\n",
        "'gs://kds-1bc45eb2a6dcbb73ace5842a7b5c01effd9a3230f9b8c73314a26d74'\n",
        "]\n",
        "\n",
        "DICT_PATH = 'gs://kds-baad38a91ebb50744b66774d8ba77e8d3df2ce699dc5f8ad2d5dc6f6/train_with_metadata.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK8Kb5zIFIab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "752d4f80-0add-477f-85d6-1825bac5886a"
      },
      "source": [
        "SEED = 100\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "FILENAMES=[]\n",
        "for GCS_PATH in GCS_PATHS:     \n",
        "    FILENAMES += tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
        "TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(FILENAMES, test_size = 0.02, random_state = SEED)\n",
        "training_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in TRAINING_FILENAMES]\n",
        "validation_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in VALIDATION_FILENAMES]\n",
        "print(training_groups, validation_groups)\n",
        "\n",
        "df = pd.read_csv(DICT_PATH)\n",
        "def count_data_items(filenames):\n",
        "    records = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    n = df[df['fold'].isin(records)].shape[0]\n",
        "    return n\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES  = count_data_items(VALIDATION_FILENAMES)\n",
        "print(f'Training with {NUM_TRAINING_IMAGES} images')\n",
        "print(f'Validating with {NUM_VALIDATION_IMAGES} images')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 12, 13, 6, 10, 5, 2, 4, 0, 11, 7, 3, 14, 8] [9]\n",
            "Training with 1671055 images\n",
            "Validating with 119539 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbC4Wt47QFSE"
      },
      "source": [
        "# TRAIN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfRfgJt-2AF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cdca0f56-9cc9-4840-b71b-498ed8f022ba"
      },
      "source": [
        "seed_everything(SEED)\n",
        "\n",
        "# train\n",
        "df_train = pd.read_csv(DICT_PATH)\n",
        "df_train = df_train[df_train.fold!=9]\n",
        "df_train = df_train.sort_values(by=['StudyInstanceUID','image_position'])\n",
        "\n",
        "import pickle\n",
        "with open(os.path.join(PATH, f'mapping_train_set.p'), 'rb') as fp:\n",
        "    dict_ = pickle.load(fp)\n",
        "\n",
        "print(len(dict_),len(df_train))\n",
        "\n",
        "df_studywise = df_train.groupby('StudyInstanceUID').mean()\n",
        "df_studywise['count'] = df_train.groupby('StudyInstanceUID')['SOPInstanceUID'].count()\n",
        "df_studywise['SOPInstanceUID'] = df_train.groupby('StudyInstanceUID')['SOPInstanceUID'].unique()\n",
        "df_studywise['SOPInstanceUID'] = df_studywise['SOPInstanceUID'].apply(lambda x:list(x))\n",
        "df_studywise['predictions'] = df_studywise['SOPInstanceUID'].apply(lambda x:np.stack([dict_[i] for i in x], axis=0))\n",
        "\n",
        "print(df_studywise.shape)\n",
        "\n",
        "del dict_\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1671055 1671055\n",
            "(6794, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMV0z4iWTwld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d92255b7-8e5d-4654-b2bb-c36442085e31"
      },
      "source": [
        "# val\n",
        "df_val = pd.read_csv(DICT_PATH)\n",
        "df_val = df_val[df_val.fold==9]\n",
        "df_val = df_val.sort_values(by=['StudyInstanceUID','image_position'])\n",
        "\n",
        "import pickle\n",
        "with open(os.path.join(PATH, f'mapping_validation_set.p'), 'rb') as fp:\n",
        "    dict_val = pickle.load(fp)\n",
        "\n",
        "print(len(dict_val),len(df_val))\n",
        "\n",
        "df_studywise_val = df_val.groupby('StudyInstanceUID').mean()\n",
        "df_studywise_val['count'] = df_val.groupby('StudyInstanceUID')['SOPInstanceUID'].count()\n",
        "df_studywise_val['SOPInstanceUID'] = df_val.groupby('StudyInstanceUID')['SOPInstanceUID'].unique()\n",
        "df_studywise_val['SOPInstanceUID'] = df_studywise_val['SOPInstanceUID'].apply(lambda x:list(x))\n",
        "df_studywise_val['predictions'] = df_studywise_val['SOPInstanceUID'].apply(lambda x:np.stack([dict_val[i] for i in x], axis=0))\n",
        "\n",
        "print(df_studywise_val.shape)\n",
        "print(df_studywise_val['predictions'][0].shape)\n",
        "\n",
        "del dict_val\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "119539 119539\n",
            "(485, 24)\n",
            "(230, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBAMSYI2AySE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5645226d-8da6-4dfe-95b3-eedca7eaa2a6"
      },
      "source": [
        "temp_train = df_studywise[df_studywise['count']<=300]\n",
        "temp_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6138, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSefDh_4gOx"
      },
      "source": [
        "def exam_level_loss(y_true,y_pred):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = tf.clip_by_value(y_pred,epsilon,1-epsilon)\n",
        "    weights = tf.constant([ 0.0736196319,\n",
        "                            0.09202453988, \n",
        "                            0.1042944785, \n",
        "                            0.1042944785, \n",
        "                            0.1877300613, \n",
        "                            0.06257668712, \n",
        "                            0.06257668712,\n",
        "                            0.2346625767,\n",
        "                            0.0782208589],dtype=tf.float32)\n",
        "    loss = -(y_true*tf.math.log(y_pred) + (1-y_true)*tf.math.log(1-y_pred))\n",
        "    loss = tf.reduce_sum(loss*weights, axis=1)\n",
        "    loss = tf.reduce_mean(loss, axis=0)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngGLN8hPaGxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fec368a-6797-4f9b-e6af-ceccc2691809"
      },
      "source": [
        "RETRAIN = True\n",
        "EPOCHS = 10\n",
        "MODEL_PATH = 'bilstm_epoch-10_loss-0.3208_valloss-0.2900.h5'\n",
        "INITIAL_EPOCH = 0\n",
        "EMBEDDING_DIM = 128\n",
        "BATCH_SIZE = 50\n",
        "LR = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(1024, return_sequences=True), input_shape=(None,EMBEDDING_DIM)))\n",
        "model.add(Bidirectional(LSTM(1024, return_sequences=False)))\n",
        "model.add(Dense(9, activation='sigmoid'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(learning_rate = 1e-6)\n",
        "opt = tf.keras.optimizers.SGD(learning_rate = LR, momentum=0.99)\n",
        "model.compile(loss=exam_level_loss, \n",
        "              optimizer=opt,\n",
        "              metrics = ['AUC'])\n",
        "if RETRAIN:\n",
        "    print('Loading model...')\n",
        "    model.load_weights(os.path.join(PATH, MODEL_PATH))\n",
        "\n",
        "ordered_columns = ['negative_exam_for_pe','indeterminate','chronic_pe','acute_and_chronic_pe','central_pe','leftsided_pe','rightsided_pe','rv_lv_ratio_gte_1','rv_lv_ratio_lt_1' ]\n",
        "#ordered_columns = ['leftsided_pe']\n",
        "\n",
        "def train_generator():\n",
        "    X = []\n",
        "    Y = []\n",
        "    while True:\n",
        "        for index,row in temp_train.iterrows():\n",
        "            y_train = tf.convert_to_tensor(row[ordered_columns].values.astype(np.float32))\n",
        "            x_train = tf.convert_to_tensor(row['predictions'])\n",
        "            length = x_train.shape[0]\n",
        "            left = (300-length)//2\n",
        "            right = 300-length-left\n",
        "            x_train = tf.pad(x_train, [[left,right],[0,0]], constant_values=0)\n",
        "            X.append(x_train)\n",
        "            Y.append(y_train)\n",
        "            if len(X)==BATCH_SIZE:\n",
        "                x_batch = tf.stack(X, axis=0)\n",
        "                y_batch = tf.stack(Y, axis=0)\n",
        "                yield x_batch, y_batch\n",
        "                del X, Y\n",
        "                X = []\n",
        "                Y = []\n",
        "\n",
        "def val_generator():\n",
        "    while True:\n",
        "        for index,row in df_studywise_val.iterrows():\n",
        "            x_val = tf.convert_to_tensor(row['predictions'])\n",
        "            x_val = tf.expand_dims(x_val,axis=0)\n",
        "            y_val = tf.convert_to_tensor(row[ordered_columns].values.astype(np.float32))\n",
        "            y_val = tf.expand_dims(y_val,axis=0)\n",
        "            yield x_val, y_val\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(PATH, 'bilstm_epoch-{epoch}_loss-{loss:.4f}_valloss-{val_loss:.4f}.h5'), \n",
        "                                                 save_best_only = False, \n",
        "                                                 save_weights_only = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIAjpQWrEL9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "65c3496b-62db-421d-dd8a-6ccd19f3730d"
      },
      "source": [
        "model.fit(train_generator(), steps_per_epoch=len(temp_train)//BATCH_SIZE, \n",
        "          validation_data=val_generator(), validation_steps=len(df_studywise_val),\n",
        "          callbacks=[checkpoint],epochs=EPOCHS, verbose=1, initial_epoch=INITIAL_EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/122 [..............................] - ETA: 3:45 - loss: 0.2965 - auc: 0.8365WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.9673s vs `on_train_batch_end` time: 1.4575s). Check your callbacks.\n",
            "122/122 [==============================] - 392s 3s/step - loss: 0.3215 - auc: 0.8202 - val_loss: 0.2899 - val_auc: 0.8416\n",
            "Epoch 2/10\n",
            "122/122 [==============================] - 389s 3s/step - loss: 0.3211 - auc: 0.8206 - val_loss: 0.2899 - val_auc: 0.8406\n",
            "Epoch 3/10\n",
            "122/122 [==============================] - 389s 3s/step - loss: 0.3201 - auc: 0.8213 - val_loss: 0.2898 - val_auc: 0.8409\n",
            "Epoch 4/10\n",
            "122/122 [==============================] - 390s 3s/step - loss: 0.3211 - auc: 0.8208 - val_loss: 0.2897 - val_auc: 0.8408\n",
            "Epoch 5/10\n",
            "122/122 [==============================] - 390s 3s/step - loss: 0.3207 - auc: 0.8211 - val_loss: 0.2898 - val_auc: 0.8406\n",
            "Epoch 6/10\n",
            "122/122 [==============================] - 386s 3s/step - loss: 0.3204 - auc: 0.8213 - val_loss: 0.2900 - val_auc: 0.8411\n",
            "Epoch 7/10\n",
            "122/122 [==============================] - 388s 3s/step - loss: 0.3204 - auc: 0.8214 - val_loss: 0.2903 - val_auc: 0.8405\n",
            "Epoch 8/10\n",
            "122/122 [==============================] - 388s 3s/step - loss: 0.3210 - auc: 0.8211 - val_loss: 0.2907 - val_auc: 0.8406\n",
            "Epoch 9/10\n",
            "122/122 [==============================] - 390s 3s/step - loss: 0.3200 - auc: 0.8216 - val_loss: 0.2912 - val_auc: 0.8404\n",
            "Epoch 10/10\n",
            "122/122 [==============================] - 390s 3s/step - loss: 0.3198 - auc: 0.8220 - val_loss: 0.2916 - val_auc: 0.8409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f80cc035898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nxl-Agj_aRC"
      },
      "source": [
        "# FINAL VALIDATION SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssGLZvB3aPbh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f08959a2-573e-427a-b5a5-fecc9d186d56"
      },
      "source": [
        "IMAGE_SCORE = 0.27\n",
        "EXAM_SCORE = 0.23\n",
        "def final_score(image_score, exam_score, q_i_sum, count):\n",
        "    score = (count*exam_score)+(q_i_sum*0.07361963*image_score)\n",
        "    score = score/((q_i_sum*0.07361963)+count)\n",
        "    return score\n",
        "temp_df = df[df.fold==9]\n",
        "final_score(IMAGE_SCORE, EXAM_SCORE, temp_df['q_i'].sum(), temp_df['StudyInstanceUID'].nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24865383161695528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VdR5-guRfOV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}